# -*- coding: utf-8 -*-
"""巨量期末v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WwLT518e4yQvnJhPj1S8K44EilTh3GTw
"""

# Deep Embedded Clustering (DEC) - Full Version

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import pandas as pd
import numpy as np
import os
import random

def set_seed(seed):
    os.environ['PYTHONHASHSEED'] = str(seed)
    os.environ['OMP_NUM_THREADS'] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)  # 多 GPU 時使用
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


# 呼叫
SEED=40
set_seed(SEED)


# 設定 numpy
np.random.seed(SEED)

# 設定 torch（CPU）
torch.manual_seed(SEED)
torch.use_deterministic_algorithms(True)

# 設定 DataLoader
g = torch.Generator()
g.manual_seed(SEED)

# ========== 1. Load and preprocess data ==========
# 修改点1: 加载两个数据集并分别标准化
df_public = pd.read_csv('public_data.csv')  # 4个特征
public_features = ['1', '2', '3', '4']  # 调整特征名
scaler_public = StandardScaler()
X_public_scaled = scaler_public.fit_transform(df_public[public_features])
X_public_tensor = torch.tensor(X_public_scaled, dtype=torch.float32)

# 新增私有数据集处理
df_private = pd.read_csv('private_data.csv')  # 6个特征
private_features = ['1', '2', '3', '4', '5', '6']  # 调整特征名
scaler_private = StandardScaler()
X_private_scaled = scaler_private.fit_transform(df_private[private_features])
X_private_tensor = torch.tensor(X_private_scaled, dtype=torch.float32)

# 修改点2: 创建两个数据集的DataLoader
public_dataset = TensorDataset(X_public_tensor)
private_dataset = TensorDataset(X_private_tensor)

public_loader = DataLoader(public_dataset, batch_size=512, shuffle=True,generator=g)
# 私有数据使用更大的batch size
private_loader = DataLoader(private_dataset, batch_size=2048, shuffle=True,generator=g)

# ========== 2. Define Autoencoder ==========
# 修改点3: 重写为双分支自编码器
class DualBranchAutoencoder(nn.Module):
    def __init__(self, public_dim=4, private_dim=6, latent_dim=8):
        super().__init__()

        # 公共数据分支
        self.public_encoder = nn.Sequential(
            nn.Linear(public_dim, 16),
            nn.ReLU(),
            nn.Linear(16, 32),
            nn.ReLU(),
            nn.Linear(32, latent_dim)  # 统一潜在空间维度
        )
        # 私有数据分支
        self.private_encoder = nn.Sequential(
            nn.Linear(private_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 64),
            nn.ReLU(),
            nn.Linear(64, latent_dim)  # 统一潜在空间维度
        )
        # 修改点4: 共享解码器结构
        self.shared_decoder = nn.Sequential(
            nn.Linear(latent_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 16),
            nn.ReLU())

        # 特定输出头
        self.public_decoder_head = nn.Linear(16, public_dim)
        self.private_decoder_head = nn.Linear(16, private_dim)

    def forward(self, x_public, x_private):
        # 双分支编码
        z_public = self.public_encoder(x_public)
        z_private = self.private_encoder(x_private)

        # 共享解码
        shared_public = self.shared_decoder(z_public)
        shared_private = self.shared_decoder(z_private)

        # 特定重建
        x_public_recon = self.public_decoder_head(shared_public)
        x_private_recon = self.private_decoder_head(shared_private)

        return x_public_recon, x_private_recon, z_public, z_private

model = DualBranchAutoencoder()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
loss_fn = nn.MSELoss()

# ========== 3. Pretrain Autoencoder ==========
# 修改点5: 双数据集联合预训练
for epoch in range(150):  # 减少轮次
    total_loss = 0
    private_iter = iter(private_loader)  # 创建私有数据迭代器

    # [這次新增] 渐进式训练权重
    if epoch < 50:  # 第一阶段：强调public数据
        public_weight = 0.8
        private_weight = 0.2
    elif epoch < 100:  # 第二阶段：平衡权重
        public_weight = 0.5
        private_weight = 0.5
    else:  # 第三阶段：强调private数据
        public_weight = 0.2
        private_weight = 0.8

    for i, (x_public,) in enumerate(public_loader):
        try:
            x_private, = next(private_iter)
        except StopIteration:
            private_iter = iter(private_loader)
            x_private, = next(private_iter)

        # 前向传播（双输入）
        x_public_recon, x_private_recon, _, _ = model(x_public, x_private)

        # 修改点6: 联合损失计算
        loss_public = loss_fn(x_public_recon, x_public)
        loss_private = loss_fn(x_private_recon, x_private)
        loss = loss_public + loss_private

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    print(f"Epoch {epoch+1}, Pretrain Loss: {total_loss/(i+1):.6f}")

# ========== 4. Get latent features ==========
# 修改点7: 分别提取两个数据集的潜在特征
model.eval()
with torch.no_grad():
    # 公共数据
    z_public_list = []
    for batch in DataLoader(public_dataset, batch_size=1024):
        x_public, = batch
        _, _, z_public, _ = model(x_public, torch.zeros(1, 6))  # 私有分支输入占位符
        z_public_list.append(z_public)
    Z_public = torch.cat(z_public_list)

    # 私有数据
    z_private_list = []
    for batch in DataLoader(private_dataset, batch_size=2048):
        x_private, = batch
        _, _, _, z_private = model(torch.zeros(1, 4), x_private)  # 公共分支输入占位符
        z_private_list.append(z_private)
    Z_private = torch.cat(z_private_list)

# 修改点8: 合并潜在特征
Z_combined = torch.cat([Z_public, Z_private]).numpy()

# ========== 5. Initialize cluster centers ==========
# 修改点9: 使用合并数据初始化K-means
kmeans = KMeans(n_clusters=15, n_init=20,random_state=SEED)
cluster_centers = torch.tensor(kmeans.fit(Z_combined).cluster_centers_, dtype=torch.float32)

# ========== 6. Clustering layer ==========
# 保持不变
class ClusteringLayer(nn.Module):
    def __init__(self, cluster_centers):
        super().__init__()
        self.centers = nn.Parameter(cluster_centers)

    def forward(self, z):
        q = 1.0 / (1.0 + torch.sum((z.unsqueeze(1) - self.centers) ** 2, dim=2))
        q = q / torch.sum(q, dim=1, keepdim=True)
        return q

cluster_layer = ClusteringLayer(cluster_centers)

# ========== 7. Target distribution function ==========
# 保持不变
def target_distribution(q):
    weight = q ** 2 / q.sum(0)
    return (weight.T / weight.sum(1)).T

# ========== 8. Joint training ==========
# 修改点10: 创建联合索引数据集
public_indices = np.arange(len(Z_public))
private_indices = np.arange(len(Z_public), len(Z_combined))

# 修改点11: 创建联合数据加载器
combined_loader = DataLoader(
    range(len(Z_combined)),  # 伪数据集用于索引
    batch_size=4096,
    shuffle=True
)

optimizer_joint = torch.optim.Adam(
    list(model.public_encoder.parameters()) +
    list(model.private_encoder.parameters()) +
    list(cluster_layer.parameters()),
    lr=1e-4
)

for epoch in range(100):
    # 修改点12: 计算整个数据集的目标分布
    model.eval()
    cluster_layer.eval()

    with torch.no_grad():
        # 计算公共数据的q
        q_public = []
        for batch in DataLoader(public_dataset, batch_size=2048):
            x_public, = batch
            _, _, z_public, _ = model(x_public, torch.zeros(1, 6))
            q_public.append(cluster_layer(z_public))
        q_public = torch.cat(q_public)

        # 计算私有数据的q
        q_private = []
        for batch in DataLoader(private_dataset, batch_size=4096):
            x_private, = batch
            _, _, _, z_private = model(torch.zeros(1, 4), x_private)
            q_private.append(cluster_layer(z_private))
        q_private = torch.cat(q_private)

    # 合并q值
    q_combined = torch.cat([q_public, q_private])
    p_combined = target_distribution(q_combined).detach()

    # 修改点13: 动态批次训练
    model.train()
    cluster_layer.train()

    total_loss = 0
    for batch_idx in combined_loader:
        # 识别公共/私有数据
        is_public = np.isin(batch_idx.numpy(), public_indices)
        is_private = np.isin(batch_idx.numpy(), private_indices)

        p_batch = p_combined[batch_idx]

        # 准备数据
        batch_public = X_public_tensor[batch_idx[is_public]] if any(is_public) else None
        batch_private = X_private_tensor[batch_idx[is_private] - len(Z_public)] if any(is_private) else None

        # 前向传播
        optimizer_joint.zero_grad()
        batch_loss = 0

        if batch_public is not None:
            _, _, z_public, _ = model(batch_public, torch.zeros(1, 6))
            q_public = cluster_layer(z_public)
            loss_public = torch.nn.functional.kl_div(q_public.log(), p_batch[is_public], reduction='batchmean')
            batch_loss += loss_public

        if batch_private is not None:
            _, _, _, z_private = model(torch.zeros(1, 4), batch_private)
            q_private = cluster_layer(z_private)
            loss_private = torch.nn.functional.kl_div(q_private.log(), p_batch[is_private], reduction='batchmean')
            batch_loss += loss_private

        if batch_public is not None or batch_private is not None:
            batch_loss.backward()
            optimizer_joint.step()
            total_loss += batch_loss.item()

    print(f"Epoch {epoch+1}, Joint Loss: {total_loss/len(combined_loader):.6f}")

# ========== 9. Get final clusters ==========
# 修改点14: 分别获取两个数据集的分群结果
model.eval()
cluster_layer.eval()

with torch.no_grad():
    # 公共数据分群
    _, _, z_public, _ = model(X_public_tensor, torch.zeros(1, 6))
    q_public = cluster_layer(z_public)
    public_clusters = q_public.argmax(dim=1).numpy()

    # 私有数据分群
    private_clusters = []
    for batch in DataLoader(private_dataset, batch_size=4096):
        x_private, = batch
        _, _, _, z_private = model(torch.zeros(1, 4), x_private)
        q_private = cluster_layer(z_private)
        private_clusters.append(q_private.argmax(dim=1))
    private_clusters = torch.cat(private_clusters).numpy()

# 保存结果
np.save('public_clusters.npy', public_clusters)
np.save('private_clusters.npy', private_clusters)

public_clusters

from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# PCA 降到 2 維
pca = PCA(n_components=3)
z_pca = pca.fit_transform(q_combined.numpy())

# 畫圖
import plotly.express as px
import pandas as pd

z_df = pd.DataFrame(z_pca, columns=['PC1', 'PC2', 'PC3'])
z_df['label'] = np.concatenate([public_clusters, private_clusters])

fig = px.scatter_3d(
    z_df,
    x='PC1', y='PC2', z='PC3',
    color='label',
    title='DEC Clustered Latent Space (PCA 3D)',
    size_max=5  # 最大點大小限制
)
fig.update_traces(marker=dict(size=1))  # 固定點大小為3
fig.show()

print(z_df['label'].value_counts())
z_df

len(public_clusters)

z_df['id']=np.arange(1, len(public_clusters)+len(private_clusters) + 1)


public_submission = z_df[['id','label']][:len(public_clusters)]
private_submission = z_df[['id','label']][len(public_clusters):]
public_submission.to_csv('public_submission.csv', index=False)

public_submission